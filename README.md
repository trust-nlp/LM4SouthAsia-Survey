# LM4SouthAsia-Survey
A curated list of papers and resources for language models (LLMs) for Low-Resourced Languages in South Asia

Despite the rise of large language models (LLMs), South Asian languages still struggle with limited resources, code-mixing, and diversity, making it necessary to develop inclusive resources for these languages. This repository brings together models, adaptation strategies, and resources on bias and evaluation to help bridge the gap. 

We aim to record and provide a structured overview of existing resources to promote future research work for improving NLP technologies in South Asia.  

This repository is organized into three main sections:

- **LLMs and Model Resources**
- **Adaptation and Fine-Tuning Techniques**
- **Bias and Evaluation in South Asian NLP**


## 1.  Models

### 1.1  Multilingual LLMs
- IndicBART: A Pre-trained Model for Indic Natural Language Generation 
- AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese
- IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian languages.
- Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages
- IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages
- IndicIRSuite: Multilingual dataset and neural information models for Indian languages.
- RomanSetu: Efficiently un- locking multilingual capabilities of large language models via Romanization
- Exploiting language relatedness for low web-resource language model adaptation: An indic languages study
- HindiLLM: Large Language Model for Hindi
- Mixed-Distil-BERT: Code-mixed Language Modeling for Bangla, English, and Hindi
- Development of Pre-Trained Transformer-based Models for the Nepali Language
- TigerLLM - A Family of Bangla Large Language Models
- L3Cube-MahaCorpus and MahaBERT: Marathi Monolingual Corpus, Marathi BERT Language Models, and Resources
  
### 1.2  Task-Specific Fine-Tuned Models
- Application of Quantum Recurrent Neural Network in Low-Resource Language Text Classification
- Dual Channel LM for Hope Speech Detection in low-resourced Kannada
- IndicIRSuite: Multilingual Dataset and Neural Information Models for Indian Languages
- IndicTrans2: Towards High-Quality and Accessible Machine Translation Models for all 22 Scheduled Indian Languages
- TPPoet: Transformer-Based Persian Poem Generation using Minimal Data and Advanced Decoding Techniques
- Nepali Encoder Transformers: An Analysis of Auto Encoding Transformer Language Models for Nepali Text Classification
- Predicting multi-label emojis, emotions, and sentiments in code-mixed texts using an emojifying sentiments framework
- Multi-FAct: Assessing Factuality of Multilingual LLMs using FActScore
- Multimodal Machine Translation for Low-Resource Indic Languages: A Chain-of-Thought Approach Using Large Language Models
- Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages
- IndIE: A Multilingual Open Information Extraction Tool For Indic Languages
- Unified NMT models for the Indian subcontinent, transcending script-barriers
- 
### 1.3  Domain-Specific Models
- MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries
- AI-Tutor: Interactive Learning of Ancient Knowledge from Low-Resource Languages

## 2.  Model Adaptation Methods & Learning Strategies

### 2.1  Code-mixed Adaptations


### 2.2  Supervised Multilingual Transfer Learning


### 2.3  Distillation and parameter-efficient finetuning (PEFT)

## 3.  Bias, Fairness & Evaluation

### 3.1  Sociocultural Bias in NLP
### 3.2  Evaluation Metrics
